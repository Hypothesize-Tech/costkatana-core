import { ModelPricingConfig, PricingUnit } from '../pricing-data';

export const MISTRAL_PRICING: ModelPricingConfig[] = [
  // Premier Models
  {
    modelId: 'mistral-medium-latest',
    modelName: 'Mistral Medium 3',
    provider: 'Mistral AI',
    inputPrice: 0.40,
    outputPrice: 2.00,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['text', 'analysis', 'reasoning', 'enterprise'],
    category: 'text',
    isLatest: true,
    notes: 'State-of-the-art performance. Simplified enterprise deployments. Cost-efficient.'
  },
  {
    modelId: 'magistral-medium-latest',
    modelName: 'Magistral Medium (Preview)',
    provider: 'Mistral AI',
    inputPrice: 2.00,
    outputPrice: 5.00,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Thinking model excelling in domain-specific, transparent, and multilingual reasoning.'
  },
  {
    modelId: 'codestral-latest',
    modelName: 'Codestral',
    provider: 'Mistral AI',
    inputPrice: 0.30,
    outputPrice: 0.90,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 32000,
    capabilities: ['code', 'programming', 'multilingual-code'],
    category: 'code',
    isLatest: true,
    notes: 'Lightweight, fast, and proficient in over 80 programming languages.'
  },
  {
    modelId: 'devstral-medium-2507',
    modelName: 'Devstral Medium',
    provider: 'Mistral AI',
    inputPrice: 0.40,
    outputPrice: 2.00,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['code', 'agents', 'advanced-coding'],
    category: 'code',
    isLatest: true,
    notes: 'Enhanced model for advanced coding agents.'
  },
  {
    modelId: 'mistral-ocr-latest',
    modelName: 'Document AI & OCR',
    provider: 'Mistral AI',
    inputPrice: 1.00, // OCR per 1000 pages
    outputPrice: 3.00, // Annotations per 1000 pages
    unit: PricingUnit.PerRequest,
    contextWindow: 0,
    capabilities: ['ocr', 'document-understanding', 'annotations'],
    category: 'document',
    isLatest: true,
    notes: 'World\'s best document understanding API. OCR: $1/1000 pages, Annotations: $3/1000 pages'
  },
  {
    modelId: 'mistral-saba-latest',
    modelName: 'Mistral Saba',
    provider: 'Mistral AI',
    inputPrice: 0.20,
    outputPrice: 0.60,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['text', 'custom-trained', 'regional'],
    category: 'text',
    isLatest: true,
    notes: 'Custom-trained model to serve specific geographies, markets, and customers.'
  },
  {
    modelId: 'mistral-large-latest',
    modelName: 'Mistral Large',
    provider: 'Mistral AI',
    inputPrice: 2.00,
    outputPrice: 6.00,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['text', 'reasoning', 'complex-tasks'],
    category: 'text',
    isLatest: true,
    notes: 'Top-tier reasoning for high-complexity tasks and sophisticated problems.'
  },
  {
    modelId: 'pixtral-large-latest',
    modelName: 'Pixtral Large',
    provider: 'Mistral AI',
    inputPrice: 2.00,
    outputPrice: 6.00,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['vision', 'multimodal', 'reasoning'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Vision-capable large model with frontier reasoning capabilities.'
  },
  {
    modelId: 'ministral-8b-latest',
    modelName: 'Ministral 8B 24.10',
    provider: 'Mistral AI',
    inputPrice: 0.10,
    outputPrice: 0.10,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['text', 'edge', 'on-device'],
    category: 'text',
    isLatest: true,
    notes: 'Powerful model for on-device use cases.'
  },
  {
    modelId: 'ministral-3b-latest',
    modelName: 'Ministral 3B 24.10',
    provider: 'Mistral AI',
    inputPrice: 0.04,
    outputPrice: 0.04,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['text', 'edge', 'efficient'],
    category: 'text',
    isLatest: true,
    notes: 'Most efficient edge model.'
  },
  {
    modelId: 'codestral-embed-2505',
    modelName: 'Codestral Embed',
    provider: 'Mistral AI',
    inputPrice: 0.15,
    outputPrice: 0.15,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 8192,
    capabilities: ['embedding', 'code'],
    category: 'embedding',
    isLatest: true,
    notes: 'State-of-the-art embedding model for code.'
  },
  {
    modelId: 'mistral-embed',
    modelName: 'Mistral Embed',
    provider: 'Mistral AI',
    inputPrice: 0.10,
    outputPrice: 0.10,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 8192,
    capabilities: ['embedding', 'text'],
    category: 'embedding',
    isLatest: true,
    notes: 'State-of-the-art model for extracting representation of text extracts.'
  },
  {
    modelId: 'mistral-moderation-latest',
    modelName: 'Mistral Moderation 24.11',
    provider: 'Mistral AI',
    inputPrice: 0.10,
    outputPrice: 0.10,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 32000,
    capabilities: ['moderation', 'classification'],
    category: 'moderation',
    isLatest: true,
    notes: 'A classifier service for text content moderation.'
  },
  // Open Models
  {
    modelId: 'mistral-small-latest',
    modelName: 'Mistral Small 3.2',
    provider: 'Mistral AI',
    inputPrice: 0.10,
    outputPrice: 0.30,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source'],
    category: 'multimodal',
    isLatest: true,
    notes: 'SOTA. Multimodal. Multilingual. Apache 2.0.'
  },
  {
    modelId: 'magistral-small-latest',
    modelName: 'Magistral Small',
    provider: 'Mistral AI',
    inputPrice: 0.50,
    outputPrice: 1.50,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Thinking model excelling in domain-specific, transparent, and multilingual reasoning.'
  },
  {
    modelId: 'devstral-small-2507',
    modelName: 'Devstral Small',
    provider: 'Mistral AI',
    inputPrice: 0.10,
    outputPrice: 0.30,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['code', 'agents', 'open-source'],
    category: 'code',
    isLatest: true,
    notes: 'The best open-source model for coding agents.'
  },
  {
    modelId: 'pixtral-12b',
    modelName: 'Pixtral 12B',
    provider: 'Mistral AI',
    inputPrice: 0.15,
    outputPrice: 0.15,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['vision', 'multimodal', 'small'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Vision-capable small model.'
  },
  {
    modelId: 'mistral-nemo',
    modelName: 'Mistral NeMo',
    provider: 'Mistral AI',
    inputPrice: 0.15,
    outputPrice: 0.15,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 128000,
    capabilities: ['text', 'code', 'specialized'],
    category: 'code',
    isLatest: true,
    notes: 'State-of-the-art Mistral model trained specifically for code tasks.'
  },
  {
    modelId: 'open-mistral-7b',
    modelName: 'Mistral 7B',
    provider: 'Mistral AI',
    inputPrice: 0.25,
    outputPrice: 0.25,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 32000,
    capabilities: ['text', 'open-source', 'fast'],
    category: 'text',
    isLatest: false,
    notes: 'A 7B transformer model, fast-deployed and easily customisable.'
  },
  {
    modelId: 'open-mixtral-8x7b',
    modelName: 'Mixtral 8x7B',
    provider: 'Mistral AI',
    inputPrice: 0.70,
    outputPrice: 0.70,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 32000,
    capabilities: ['text', 'mixture-of-experts', 'open-source'],
    category: 'text',
    isLatest: false,
    notes: 'A 7B sparse Mixture-of-Experts (SMoE). Uses 12.9B active parameters out of 45B total.'
  },
  {
    modelId: 'open-mixtral-8x22b',
    modelName: 'Mixtral 8x22B',
    provider: 'Mistral AI',
    inputPrice: 2.00,
    outputPrice: 6.00,
    unit: PricingUnit.Per1MTokens,
    contextWindow: 65000,
    capabilities: ['text', 'mixture-of-experts', 'open-source', 'high-performance'],
    category: 'text',
    isLatest: false,
    notes: 'Most performant open model. A 22B sparse Mixture-of-Experts (SMoE). Uses only 39B active parameters out of 141B.'
  }
]; 